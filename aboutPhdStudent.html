<!DOCTYPE html>
<html lang = "en" >
<head>
<title> PhD Student </title>
 <link rel="stylesheet" type="text/css" href="cssFile.css">

</head>

<body>
<div>
<t1>
  About Andrea Gadotti
</t1>
</div>

<div>



<p1><br>
Andrea Gadotti has a bachelor's degree in mathematics and a master's degree in mathematical logic from the University of Turin. His research topic is computational privacy, with which he aims to have a direct impact on the world while working as a scientist.
<br> <br> </p1>



<p1>
The PhD student authored (alongside members of his research team) a paper in which they presented a privacy attack on a “sticky noise” system called Diffix, developed by the startup Aircloak and researchers from the Max Planck Institute for Software Systems. Diffix’s proprietary approach adds static noise (random) and dynamic noise (based on the query and the query results).
They show how an attacker who knows attributes uniquely identifying a person in the dataset can figure out sensitive information about the person. The attack goes as follows:
<br>
1) Ask questions similar enough that the answers share the static noise, which can then be eliminated.
<br>
2) Run a likelihood ratio test to figure out the probability of the dynamic noise having different distributions (depending on the the value of the attribute the attacker wants to find).
<br>
3) Improve the accuracy of the method by designing other queries equivalent to those already done.
<br>
The authors consider the main contribution to be the method of exploiting the noise added by Diffix. Considering the general academic intention is to develop a mathematically near-perfect solution for preserving privacy, many believe that differential privacy will not become viable (including Paul Francis, the co-founder of Aircloak, who calls it “the most over-hyped technology I have ever seen @link https://iapp.org/news/a/differential-privacy-at-the-end-of-the-rainbow/”).
</p1>
</div>

</body>

</html>
